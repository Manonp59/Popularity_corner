{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('df_model_sans_meteo2.csv',index_col=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(['box_office_first_week'],axis=1)\n",
    "y = df['box_office_first_week']\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y, train_size=0.9,shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['duration', 'nationality', 'views', 'budget', 'season', 'is_holiday',\n",
       "       'proportion_stars_actors', 'proportion_stars_producers',\n",
       "       'proportion_stars_director', 'distributor_avg_frequency',\n",
       "       'genre_action', 'genre_animation', 'genre_arts martiaux',\n",
       "       'genre_aventure', 'genre_biopic', 'genre_bollywood', 'genre_comédie',\n",
       "       'genre_comédie dramatique', 'genre_comédie musicale', 'genre_divers',\n",
       "       'genre_drame', 'genre_epouvante-horreur', 'genre_erotique',\n",
       "       'genre_espionnage', 'genre_expérimental', 'genre_famille',\n",
       "       'genre_fantastique', 'genre_guerre', 'genre_historique',\n",
       "       'genre_judiciaire', 'genre_musical', 'genre_policier', 'genre_péplum',\n",
       "       'genre_romance', 'genre_science fiction', 'genre_sport event',\n",
       "       'genre_thriller', 'genre_western'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-31 11:14:03,090] A new study created in memory with name: no-name-bb155890-f1f8-44ac-84f5-76603077363c\n",
      "[I 2023-07-31 11:14:03,777] Trial 0 finished with value: 0.35414310816754224 and parameters: {'n_estimators': 200, 'criterion': 'poisson', 'max_depth': 14, 'min_samples_split': 13, 'min_samples_leaf': 8, 'max_features': 'log2', 'bootstrap': True}. Best is trial 0 with value: 0.35414310816754224.\n",
      "[I 2023-07-31 11:14:04,566] Trial 1 finished with value: 0.38471698312233193 and parameters: {'n_estimators': 300, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 1 with value: 0.38471698312233193.\n",
      "[I 2023-07-31 11:14:04,787] Trial 2 finished with value: 0.24798014233678967 and parameters: {'n_estimators': 100, 'criterion': 'friedman_mse', 'max_depth': 4, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'log2', 'bootstrap': True}. Best is trial 1 with value: 0.38471698312233193.\n",
      "[I 2023-07-31 11:14:05,208] Trial 3 finished with value: 0.45592819728495226 and parameters: {'n_estimators': 100, 'criterion': 'squared_error', 'max_depth': 15, 'min_samples_split': 19, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'bootstrap': False}. Best is trial 3 with value: 0.45592819728495226.\n",
      "[I 2023-07-31 11:14:06,157] Trial 4 finished with value: 0.4006761941334117 and parameters: {'n_estimators': 300, 'criterion': 'squared_error', 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 3 with value: 0.45592819728495226.\n",
      "[I 2023-07-31 11:14:06,614] Trial 5 finished with value: 0.341976686598341 and parameters: {'n_estimators': 200, 'criterion': 'squared_error', 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}. Best is trial 3 with value: 0.45592819728495226.\n",
      "[I 2023-07-31 11:14:07,385] Trial 6 finished with value: 0.40396475642973195 and parameters: {'n_estimators': 300, 'criterion': 'friedman_mse', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}. Best is trial 3 with value: 0.45592819728495226.\n",
      "[I 2023-07-31 11:14:08,408] Trial 7 finished with value: 0.42455909684375737 and parameters: {'n_estimators': 300, 'criterion': 'squared_error', 'max_depth': 15, 'min_samples_split': 17, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'bootstrap': True}. Best is trial 3 with value: 0.45592819728495226.\n"
     ]
    }
   ],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Définir les paramètres du préprocesseur\n",
    "numerical_features = ['duration', 'views', 'budget','proportion_stars_actors', 'proportion_stars_producers', 'proportion_stars_director', 'distributor_avg_frequency']\n",
    "categorical_features = ['nationality', 'season', 'is_holiday']\n",
    "\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# Définir la fonction objectif pour Optuna\n",
    "def objective(trial):\n",
    "    # Définir les hyperparamètres à optimiser\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [100, 200, 300]),\n",
    "        'criterion': trial.suggest_categorical('criterion', ['poisson', 'friedman_mse', 'squared_error', 'absolute_error']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    # Créer le modèle ExtraTreesRegressor avec les hyperparamètres\n",
    "    model = ExtraTreesRegressor(**params)\n",
    "\n",
    "    # Créer le pipeline avec le préprocesseur et le modèle\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Entraîner le modèle\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Faire des prédictions sur les données de validation\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Calculer la métrique d'évaluation (par exemple, le R2 score)\n",
    "    score = r2_score(y_test, y_pred)\n",
    "\n",
    "    return score\n",
    "\n",
    "# Créer l'étude Optuna\n",
    "sampler = TPESampler(seed=42)  # Make the sampler behave in a deterministic way.\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "\n",
    "# Lancer l'optimisation des hyperparamètres\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Obtenir les meilleurs hyperparamètres trouvés\n",
    "best_params = study.best_params\n",
    "\n",
    "# Créer le pipeline final avec les meilleurs hyperparamètres\n",
    "best_model = ExtraTreesRegressor(**best_params)\n",
    "\n",
    "pipeline_final = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', best_model)\n",
    "])\n",
    "\n",
    "# Entraîner le modèle final sur l'ensemble des données d'entraînement\n",
    "pipeline_final.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions sur de nouvelles données\n",
    "y_pred = pipeline_final.predict(X_test)\n",
    "\n",
    "# Calculer la métrique d'évaluation finale (par exemple, le R2 score)\n",
    "final_r2 = r2_score(y_test, y_pred)\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"Meilleurs hyperparamètres trouvés :\", best_params)\n",
    "print(\"R2 Score sur les données de test :\", final_r2)\n",
    "print(final_rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Définir les paramètres du préprocesseur\n",
    "numerical_features = ['duration', 'views', 'budget','proportion_stars_actors', 'proportion_stars_producers', 'proportion_stars_director', 'distributor_avg_frequency']\n",
    "categorical_features = ['nationality', 'season', 'is_holiday']\n",
    "\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "best_params = {'n_estimators': 100, 'criterion': 'squared_error', 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': None, 'bootstrap': False}\n",
    "# Créer le modèle avec les meilleurs hyperparamètres\n",
    "model = ExtraTreesRegressor(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    criterion=best_params['criterion'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    max_features=best_params['max_features'],\n",
    "    bootstrap=best_params['bootstrap']\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor',preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/31 11:31:39 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/07/31 11:31:39 WARNING mlflow.models.evaluation.default_evaluator: Skip logging model explainability insights because the shap explainer None requires all feature values to be numeric, and each feature column must only contain scalar values.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "experiment_id = mlflow.set_experiment(\"cinema\").experiment_id\n",
    "\n",
    "run_name = \"extratree_std_onehot\"\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=run_name) as run:\n",
    "    # Log the baseline model to MLflow\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    mlflow.sklearn.log_model(pipe, run_name)\n",
    "\n",
    "    \n",
    "    model_uri = mlflow.get_artifact_uri(run_name)\n",
    "\n",
    "    # Log des paramètres\n",
    "    mlflow.log_params({'n_estimators': 100,'criterion': 'squared_error','max_depth': 14, 'min_samples_split': 3,'min_samples_leaf': 3,\n",
    "    'max_features': None,\n",
    "    'bootstrap': False})\n",
    "    \n",
    "    \n",
    "    # Log des Tags\n",
    "    mlflow.set_tag(\"model\",\"extra_tree\")\n",
    "    mlflow.set_tag(\"scaler\",\"StandardScaler\")\n",
    "    mlflow.set_tag(\"encoder\",'OneHotEncoder')\n",
    "    mlflow.set_tag('df','sans_meteo')\n",
    "    mlflow.set_tag('budget','numeric')\n",
    "\n",
    "    eval_data = X_test\n",
    "    eval_data[\"label\"] = y_test\n",
    "\n",
    "    # Evaluate the logged model\n",
    "    result = mlflow.evaluate(\n",
    "        model_uri,\n",
    "        eval_data,\n",
    "        targets=\"label\",\n",
    "        model_type=\"regressor\",\n",
    "        evaluators=[\"default\"],\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('modele.pkl', 'wb') as fichier_modele:\n",
    "    pickle.dump(pipe, fichier_modele)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
